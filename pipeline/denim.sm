# File: Snakefile

import os
import pandas as pd
from pathlib import Path

# Load configuration
configfile: "config.yaml"

# Validate embedding parameter
VALID_EMBEDDINGS = ["RTD", "CGR", "merge"]
if "embedding" not in config:
    raise ValueError("'embedding' parameter must be specified in config.yaml")
if config["embedding"] not in VALID_EMBEDDINGS:
    raise ValueError(f"'embedding' must be one of: {VALID_EMBEDDINGS}")

# Validate threads parameter
if "threads" not in config:
    raise ValueError("'threads' parameter must be specified in config.yaml")
if not isinstance(config["threads"], int) or config["threads"] <= 0:
    raise ValueError("'threads' must be a positive integer")

# Validate strand parameter
if "strand" not in config:
    raise ValueError("'strand' parameter must be specified in config.yaml")

# Validate RTD-specific parameters if RTD is being used
if config["embedding"] in ["RTD", "merge"]:
    if "k" not in config:
        raise ValueError("'k' parameter must be specified for RTD embedding")
    if "alphabet" not in config:
        raise ValueError("'alphabet' parameter must be specified for RTD embedding")

# Validate clustering parameters
clustering_params = ["min_cluster_size", "min_samples", "max_GMM", "seed"]
for param in clustering_params:
    if param not in config:
        raise ValueError(f"'{param}' parameter must be specified for clustering")

# Validate merging parameters
if config["embedding"] == "merge":
    if "overlap" not in config:
        raise ValueError("'overlap' parameter must be specified for merge mode")

# Validate bootstrapping parameters
if "n_bootstraps" not in config:
    raise ValueError("'n_bootstraps' parameter must be specified for bootstrapping")
if not isinstance(config["n_bootstraps"], int) or config["n_bootstraps"] <= 0:
    raise ValueError("'n_bootstraps' must be a positive integer")

# Validate Sleuth parameters
sleuth_params = ["parameter", "pseudocount", "alpha", "foldchange"]
for param in sleuth_params:
    if param not in config:
        raise ValueError(f"'{param}' parameter must be specified for Sleuth analysis")

# Validate numeric Sleuth parameters
if not isinstance(config["pseudocount"], (int, float)) or config["pseudocount"] <= 0:
    raise ValueError("'pseudocount' must be a positive number")
if not isinstance(config["alpha"], float) or not 0 < config["alpha"] < 1:
    raise ValueError("'alpha' must be a float between 0 and 1")
if not isinstance(config["foldchange"], (int, float)) or config["foldchange"] <= 0:
    raise ValueError("'foldchange' must be a positive number")

# Dictionary of embedding types and their output directories using mode-specific paths
if config["embedding"] == "merge":
    ACTIVE_DIRS = {
        "RTD": {
            "embed_dir": "01_RTD_embedding",
            "cluster_dir": "03_RTD_clustering",
            "bootstrap_dir": "06_RTD_bootstrapping",
            "sleuth_dir": "09_RTD_Sleuth",
            "retrieval_dir": "12_RTD_SigClusters"
        },
        "CGR": {
            "embed_dir": "02_CGR_embedding",
            "cluster_dir": "04_CGR_clustering",
            "bootstrap_dir": "07_CGR_bootstrapping",
            "sleuth_dir": "10_CGR_Sleuth",
            "retrieval_dir": "13_CGR_SigClusters"
        },
        "merge": {
            "bootstrap_dir": "08_merge_bootstrapping",
            "sleuth_dir": "11_merge_Sleuth",
            "retrieval_dir": "14_merge_SigClusters"
        }
    }
else:
    ACTIVE_DIRS = {
        config["embedding"]: {
            "embed_dir": f"01_{config['embedding']}",
            "cluster_dir": f"02_{config['embedding']}_clustering",
            "bootstrap_dir": f"03_{config['embedding']}_bootstrapping",
            "sleuth_dir": f"04_{config['embedding']}_Sleuth",
            "retrieval_dir": f"05_{config['embedding']}_SigClusters"
        }
    }

# Define what embeddings will be used
EMBEDDINGS_TO_USE = ["RTD", "CGR"] if config["embedding"] == "merge" else [config["embedding"]]

# Function to get expected outputs
def get_expected_outputs():
    outputs = []
    outputs.extend([
        "validation_complete.txt",
        "embedding_mode_reported.txt",
        "00_input/qc_merge_complete.txt"
    ])
    
    for method in EMBEDDINGS_TO_USE:
        outputs.extend([
            f"{ACTIVE_DIRS[method]['embed_dir']}/embedding_complete.txt",
            f"{ACTIVE_DIRS[method]['cluster_dir']}/clustering_complete.txt",
            f"{ACTIVE_DIRS[method]['bootstrap_dir']}/bootstrapping_complete.txt",
            f"{ACTIVE_DIRS[method]['sleuth_dir']}/sleuth_complete.txt",
            f"{ACTIVE_DIRS[method]['retrieval_dir']}/retrieval_complete.txt"
        ])
    
    if config["embedding"] == "merge":
        outputs.extend([
            "05_merging/merging_complete.txt",
            f"{ACTIVE_DIRS['merge']['bootstrap_dir']}/bootstrapping_complete.txt",
            f"{ACTIVE_DIRS['merge']['sleuth_dir']}/sleuth_complete.txt",
            f"{ACTIVE_DIRS['merge']['retrieval_dir']}/retrieval_complete.txt"
        ])
    
    return outputs

# Load metadata
def load_metadata():
    try:
        return pd.read_csv(config["metadata"], sep="\t")
    except Exception as e:
        raise ValueError(f"Error reading metadata file: {e}")

# Validate parameter exists in metadata
metadata = load_metadata()
if config["parameter"] not in metadata.columns:
    raise ValueError(f"Parameter '{config['parameter']}' not found in metadata file")

# Input validation function
def validate_input_structure():
    # Check if base directory exists
    base_dir = Path(config["base_dir"])
    if not base_dir.exists():
        raise ValueError(f"Base directory {base_dir} does not exist")
    
    # Check if input directory exists
    input_dir = base_dir / "00_input"
    if not input_dir.exists():
        raise ValueError(f"Input directory {input_dir} does not exist")
    
    # Check if metadata file exists
    metadata_path = base_dir / config["metadata"]
    if not metadata_path.exists():
        raise ValueError(f"Metadata file {metadata_path} does not exist")
    
    # Load and validate metadata
    metadata = load_metadata()
    required_columns = ["SRA", "description", "sample"]
    missing_columns = [col for col in required_columns if col not in metadata.columns]
    if missing_columns:
        raise ValueError(f"Missing required columns in metadata: {missing_columns}")
    
    # Check if QC/merge has been completed
    qc_merge_complete = (input_dir / "qc_merge_complete.txt").exists()
    
    # Validate input directory structure
    if qc_merge_complete:
        # After QC/merge, check for sample-named directories
        for sample in metadata["sample"].unique():
            sample_dir = input_dir / str(sample)
            if not sample_dir.exists():
                raise ValueError(f"Missing directory for sample: {sample_dir}")
    else:
        # Before QC/merge, check for SRA-named directories and fastq files
        for sra in metadata["SRA"]:
            sra_dir = input_dir / str(sra)
            if not sra_dir.exists():
                raise ValueError(f"Missing directory for SRA: {sra_dir}")
            
            # Check for fastq files
            r1 = sra_dir / f"{sra}_1.fastq.gz"
            r2 = sra_dir / f"{sra}_2.fastq.gz"
            if not r1.exists():
                raise ValueError(f"Missing R1 fastq file: {r1}")
            if not r2.exists():
                raise ValueError(f"Missing R2 fastq file: {r2}")

# Perform initial validation
validate_input_structure()

# Get list of all samples
metadata = load_metadata()
SAMPLES = metadata["SRA"].tolist()

# Define the target rule
rule all:
    input:
        get_expected_outputs()

# Validation rule
rule validate_inputs:
    output:
        touch("validation_complete.txt")
    run:
        validate_input_structure()
        print("Input validation completed successfully!")

# Rule to report embedding mode
rule report_embedding_mode:
    output:
        touch("embedding_mode_reported.txt")
    run:
        if config["embedding"] == "merge":
            print("\nPipeline will run in MERGE mode:")
            print("Reads will be embedded using both 'RTD' and 'CGR'.")
            print("Analysis will be performed on the individual embeddings as well as their merge.\n")
        else:
            print(f"\nPipeline will run in SINGLE EMBEDDING mode:")
            print(f"Reads will be embedded using '{config['embedding']}'\n")

# Rule for read QC and merging
rule qc_and_merge:
    input:
        "validation_complete.txt",
        "embedding_mode_reported.txt"
    output:
        touch("00_input/qc_merge_complete.txt")
    params:
        pipeline_dir = config["pipeline_dir"],
        input_dir = os.path.join(config["base_dir"], "00_input"),
        metadata = config["metadata"],
        threads = config["threads"]
    shell:
        """
        echo "\nStarting read QC and paired-end merging..."
        echo "Using {params.threads} CPUs for processing"
        echo "Input directory: {params.input_dir}"
        echo "Pipeline directory: {params.pipeline_dir}\n"
        
        {params.pipeline_dir}/filter_merge.sh \
            -p {params.input_dir} \
            -m {params.metadata} \
            -t {params.threads}
        """

# Rule for RTD embedding
rule rtd_embedding:
    input:
        "00_input/qc_merge_complete.txt"
    output:
        touch(f"{ACTIVE_DIRS['RTD']['embed_dir']}/embedding_complete.txt")
    params:
        pipeline_dir = config["pipeline_dir"],
        base_dir = config["base_dir"],
        input_dir = os.path.join(config["base_dir"], "00_input"),
        metadata = config["metadata"],
        threads = config["threads"],
        k = config["k"],
        alphabet = config["alphabet"],
        strand = config["strand"],
        output_dir = ACTIVE_DIRS['RTD']['embed_dir']
    shell:
        """
        echo "\nStarting RTD embedding..."
        echo "Using {params.threads} CPUs for processing"
        echo "Input directory: {params.input_dir}"
        echo "k-mer size: {params.k}"
        echo "Alphabet: {params.alphabet}"
        echo "Strand: {params.strand}\n"
        
        {params.pipeline_dir}/generate_rtd.sh \
            -b {params.base_dir} \
            -i {params.input_dir} \
            -p {params.pipeline_dir} \
            -m {params.metadata} \
            -k {params.k} \
            -a "{params.alphabet}" \
            -s {params.strand} \
            -t {params.threads} \
            -o "{params.output_dir}"
        """

# Rule for CGR embedding
rule cgr_embedding:
    input:
        "00_input/qc_merge_complete.txt"
    output:
        touch(f"{ACTIVE_DIRS['CGR']['embed_dir']}/embedding_complete.txt")
    params:
        pipeline_dir = config["pipeline_dir"],
        base_dir = config["base_dir"],
        input_dir = os.path.join(config["base_dir"], "00_input"),
        metadata = config["metadata"],
        threads = config["threads"],
        strand = config["strand"],
        output_dir = ACTIVE_DIRS['CGR']['embed_dir']
    shell:
        """
        echo "\nStarting CGR embedding..."
        echo "Using {params.threads} CPUs for processing"
        echo "Input directory: {params.input_dir}"
        echo "Strand: {params.strand}\n"
        
        {params.pipeline_dir}/generate_cgr.sh \
            -b {params.base_dir} \
            -i {params.input_dir} \
            -p {params.pipeline_dir} \
            -m {params.metadata} \
            -s {params.strand} \
            -t {params.threads} \
            -o "{params.output_dir}"
        """

# Rule for RTD clustering (when RTD embedding is used)
rule rtd_clustering:
    input:
        embeddings=f"{ACTIVE_DIRS['RTD']['embed_dir']}/embedding_complete.txt"
    output:
        clustering=f"{ACTIVE_DIRS['RTD']['cluster_dir']}/clustering_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        min_cluster_size = config["min_cluster_size"],
        min_samples = config["min_samples"],
        max_GMM = config["max_GMM"],
        threads = config["threads"],
        seed = config["seed"],
        input_dir = ACTIVE_DIRS['RTD']['embed_dir'],
        output_dir = ACTIVE_DIRS['RTD']['cluster_dir']
    shell:
        """
        echo "\nStarting RTD clustering..."
        echo "Input directory: {params.input_dir}"
        echo "Output directory: {params.output_dir}"
        echo "Using {params.threads} CPUs for processing"
        echo "Minimum cluster size: {params.min_cluster_size}"
        echo "Minimum samples: {params.min_samples}"
        echo "Maximum GMM components: {params.max_GMM}"
        echo "Random seed: {params.seed}\n"
        
        mkdir -p {params.output_dir}
        cd {params.output_dir}
        
        RTD_path=$(echo "$(pwd)/../{params.input_dir}")
        
        python {params.pipeline_dir}/cluster.py \
            --file_pattern "$RTD_path"'/*/*.gz' \
            --output_file clustering_results.tsv \
            --min_cluster_size {params.min_cluster_size} \
            --min_samples {params.min_samples} \
            --num_cpus {params.threads} \
            --max_GMM {params.max_GMM} \
            --seed {params.seed}
            
        touch clustering_complete.txt
        """

# Rule for CGR clustering (when CGR embedding is used)
rule cgr_clustering:
    input:
        embeddings=f"{ACTIVE_DIRS['CGR']['embed_dir']}/embedding_complete.txt"
    output:
        clustering=f"{ACTIVE_DIRS['CGR']['cluster_dir']}/clustering_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        min_cluster_size = config["min_cluster_size"],
        min_samples = config["min_samples"],
        max_GMM = config["max_GMM"],
        threads = config["threads"],
        seed = config["seed"],
        input_dir = ACTIVE_DIRS['CGR']['embed_dir'],
        output_dir = ACTIVE_DIRS['CGR']['cluster_dir']
    shell:
        """
        echo "\nStarting CGR clustering..."
        echo "Input directory: {params.input_dir}"
        echo "Output directory: {params.output_dir}"
        echo "Using {params.threads} CPUs for processing"
        echo "Minimum cluster size: {params.min_cluster_size}"
        echo "Minimum samples: {params.min_samples}"
        echo "Maximum GMM components: {params.max_GMM}"
        echo "Random seed: {params.seed}\n"
        
        mkdir -p {params.output_dir}
        cd {params.output_dir}
        
        CGR_path=$(echo "$(pwd)/../{params.input_dir}")
        
        python {params.pipeline_dir}/cluster.py \
            --file_pattern "$CGR_path"'/*/*.gz' \
            --output_file clustering_results.tsv \
            --min_cluster_size {params.min_cluster_size} \
            --min_samples {params.min_samples} \
            --num_cpus {params.threads} \
            --max_GMM {params.max_GMM} \
            --seed {params.seed}
            
        touch clustering_complete.txt
        """

# Rule for merging clusters (only in merge mode)
rule merge_clusters:
    input:
        rtd_clustering=f"{ACTIVE_DIRS['RTD']['cluster_dir']}/clustering_complete.txt",
        cgr_clustering=f"{ACTIVE_DIRS['CGR']['cluster_dir']}/clustering_complete.txt"
    output:
        merging="05_merging/merging_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        base_dir = config["base_dir"],
        overlap = config["overlap"]
    shell:
        """
        echo "\nStarting cluster merging..."
        echo "Using overlap threshold: {params.overlap}"
        
        mkdir -p 05_merging
        cd 05_merging
        
        base_path=$(echo "$(pwd)/..")
        
        python {params.pipeline_dir}/merge.py \
            --clusterings "$base_path"'/*_clustering/clustering_results.tsv' \
            --volumes "$base_path"'/*_clustering/est_volumes.tsv' \
            --overlap {params.overlap}
            
        touch merging_complete.txt
        """

# Rule for RTD bootstrapping
rule rtd_bootstrapping:
    input:
        clustering=f"{ACTIVE_DIRS['RTD']['cluster_dir']}/clustering_complete.txt"
    output:
        bootstrap=f"{ACTIVE_DIRS['RTD']['bootstrap_dir']}/bootstrapping_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        n_bootstraps = config["n_bootstraps"],
        cluster_dir = ACTIVE_DIRS['RTD']['cluster_dir'],
        bootstrap_dir = ACTIVE_DIRS['RTD']['bootstrap_dir']
    shell:
        """
        echo "\nStarting RTD bootstrapping..."
        echo "Mode: {config[embedding]}"
        echo "Input directory: {params.cluster_dir}"
        echo "Output directory: {params.bootstrap_dir}"
        echo "Number of bootstraps: {params.n_bootstraps}\n"
        
        mkdir -p {params.bootstrap_dir}
        cd {params.bootstrap_dir}
        
        RTD_clust_path=$(echo "$(pwd)/../{params.cluster_dir}")
        
        python {params.pipeline_dir}/bootstrap.py \
            --counts "$RTD_clust_path"'/table.otu' \
            --volumes "$RTD_clust_path"'/est_volumes.tsv' \
            --n_bootstraps {params.n_bootstraps}
            
        touch bootstrapping_complete.txt
        """

# Rule for CGR bootstrapping
rule cgr_bootstrapping:
    input:
        clustering=f"{ACTIVE_DIRS['CGR']['cluster_dir']}/clustering_complete.txt"
    output:
        bootstrap=f"{ACTIVE_DIRS['CGR']['bootstrap_dir']}/bootstrapping_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        n_bootstraps = config["n_bootstraps"],
        cluster_dir = ACTIVE_DIRS['CGR']['cluster_dir'],
        bootstrap_dir = ACTIVE_DIRS['CGR']['bootstrap_dir']
    shell:
        """
        echo "\nStarting CGR bootstrapping..."
        echo "Mode: {config[embedding]}"
        echo "Input directory: {params.cluster_dir}"
        echo "Output directory: {params.bootstrap_dir}"
        echo "Number of bootstraps: {params.n_bootstraps}\n"
        
        mkdir -p {params.bootstrap_dir}
        cd {params.bootstrap_dir}
        
        CGR_clust_path=$(echo "$(pwd)/../{params.cluster_dir}")
        
        python {params.pipeline_dir}/bootstrap.py \
            --counts "$CGR_clust_path"'/table.otu' \
            --volumes "$CGR_clust_path"'/est_volumes.tsv' \
            --n_bootstraps {params.n_bootstraps}
            
        touch bootstrapping_complete.txt
        """

# Rule for merged results bootstrapping
rule merged_bootstrapping:
    input:
        merging="05_merging/merging_complete.txt"
    output:
        bootstrap=f"{ACTIVE_DIRS['merge']['bootstrap_dir']}/bootstrapping_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        n_bootstraps = config["n_bootstraps"],
        merge_dir = "05_merging",
        bootstrap_dir = ACTIVE_DIRS['merge']['bootstrap_dir']
    shell:
        """
        echo "\nStarting merged results bootstrapping..."
        echo "Input directory: {params.merge_dir}"
        echo "Output directory: {params.bootstrap_dir}"
        echo "Number of bootstraps: {params.n_bootstraps}\n"
        
        mkdir -p {params.bootstrap_dir}
        cd {params.bootstrap_dir}
        
        merge_path=$(echo "$(pwd)/../{params.merge_dir}")
        
        python {params.pipeline_dir}/bootstrap.py \
            --counts "$merge_path"'/merged_table.otu' \
            --volumes "$merge_path"'/merged_est_volumes.tsv' \
            --n_bootstraps {params.n_bootstraps}
            
        touch bootstrapping_complete.txt
        """

# Rule for RTD Sleuth analysis
rule rtd_sleuth:
    input:
        bootstrap=f"{ACTIVE_DIRS['RTD']['bootstrap_dir']}/bootstrapping_complete.txt"
    output:
        sleuth=f"{ACTIVE_DIRS['RTD']['sleuth_dir']}/sleuth_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        metadata = config["metadata"],
        parameter = config["parameter"],
        pseudocount = config["pseudocount"],
        alpha = config["alpha"],
        foldchange = config["foldchange"],
        bootstrap_dir = ACTIVE_DIRS['RTD']['bootstrap_dir'],
        sleuth_dir = ACTIVE_DIRS['RTD']['sleuth_dir']
    shell:
        """
        echo "\nStarting RTD Sleuth analysis..."
        echo "Mode: {config[embedding]}"
        echo "Bootstrap directory: {params.bootstrap_dir}"
        echo "Output directory: {params.sleuth_dir}"
        echo "Parameter: {params.parameter}"
        
        mkdir -p {params.sleuth_dir}
        cd {params.sleuth_dir}
        
        base_path=$(echo "$(pwd)/..")
        rtd_bootstrap_dir=$(basename {params.bootstrap_dir})
        
        Rscript {params.pipeline_dir}/sleuth.R \
            --root "$base_path" \
            --metadata {params.metadata} \
            --bootstrap "$rtd_bootstrap_dir" \
            --pseudocount {params.pseudocount} \
            --alpha {params.alpha} \
            --fc {params.foldchange} \
            --parameter {params.parameter}
            
        touch sleuth_complete.txt
        """

# Rule for CGR Sleuth analysis
rule cgr_sleuth:
    input:
        bootstrap=f"{ACTIVE_DIRS['CGR']['bootstrap_dir']}/bootstrapping_complete.txt"
    output:
        sleuth=f"{ACTIVE_DIRS['CGR']['sleuth_dir']}/sleuth_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        metadata = config["metadata"],
        parameter = config["parameter"],
        pseudocount = config["pseudocount"],
        alpha = config["alpha"],
        foldchange = config["foldchange"],
        bootstrap_dir = ACTIVE_DIRS['CGR']['bootstrap_dir'],
        sleuth_dir = ACTIVE_DIRS['CGR']['sleuth_dir']
    shell:
        """
        echo "\nStarting CGR Sleuth analysis..."
        echo "Mode: {config[embedding]}"
        echo "Bootstrap directory: {params.bootstrap_dir}"
        echo "Output directory: {params.sleuth_dir}"
        echo "Parameter: {params.parameter}"
        
        mkdir -p {params.sleuth_dir}
        cd {params.sleuth_dir}
        
        base_path=$(echo "$(pwd)/..")
        cgr_bootstrap_dir=$(basename {params.bootstrap_dir})
        
        Rscript {params.pipeline_dir}/sleuth.R \
            --root "$base_path" \
            --metadata {params.metadata} \
            --bootstrap "$cgr_bootstrap_dir" \
            --pseudocount {params.pseudocount} \
            --alpha {params.alpha} \
            --fc {params.foldchange} \
            --parameter {params.parameter}
            
        touch sleuth_complete.txt
        """

# Rule for merged results Sleuth analysis
rule merged_sleuth:
    input:
        bootstrap=f"{ACTIVE_DIRS['merge']['bootstrap_dir']}/bootstrapping_complete.txt"
    output:
        sleuth=f"{ACTIVE_DIRS['merge']['sleuth_dir']}/sleuth_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        metadata = config["metadata"],
        parameter = config["parameter"],
        pseudocount = config["pseudocount"],
        alpha = config["alpha"],
        foldchange = config["foldchange"],
        bootstrap_dir = ACTIVE_DIRS['merge']['bootstrap_dir'],
        sleuth_dir = ACTIVE_DIRS['merge']['sleuth_dir']
    shell:
        """
        echo "\nStarting merged results Sleuth analysis..."
        echo "Bootstrap directory: {params.bootstrap_dir}"
        echo "Output directory: {params.sleuth_dir}"
        echo "Parameter: {params.parameter}"
        
        mkdir -p {params.sleuth_dir}
        cd {params.sleuth_dir}
        
        base_path=$(echo "$(pwd)/..")
        merge_bootstrap_dir=$(basename {params.bootstrap_dir})
        
        Rscript {params.pipeline_dir}/sleuth.R \
            --root "$base_path" \
            --metadata {params.metadata} \
            --bootstrap "$merge_bootstrap_dir" \
            --pseudocount {params.pseudocount} \
            --alpha {params.alpha} \
            --fc {params.foldchange} \
            --parameter {params.parameter}
            
        touch sleuth_complete.txt
        """

# Rule for RTD read retrieval
rule rtd_retrieval:
    input:
        sleuth=f"{ACTIVE_DIRS['RTD']['sleuth_dir']}/sleuth_complete.txt"
    output:
        retrieval=f"{ACTIVE_DIRS['RTD']['retrieval_dir']}/retrieval_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        threads = config["threads"],
        alpha = config["alpha"],
        foldchange = config["foldchange"],
        input_dir = "00_input",
        cluster_dir = ACTIVE_DIRS['RTD']['cluster_dir'],
        sleuth_dir = ACTIVE_DIRS['RTD']['sleuth_dir'],
        retrieval_dir = ACTIVE_DIRS['RTD']['retrieval_dir']
    shell:
        """
        echo "\nStarting RTD read retrieval..."
        echo "Mode: {config[embedding]}"
        echo "Cluster directory: {params.cluster_dir}"
        echo "Sleuth directory: {params.sleuth_dir}"
        echo "Output directory: {params.retrieval_dir}"
        
        mkdir -p {params.retrieval_dir}
        cd {params.retrieval_dir}
        
        RTD_clust_path=$(echo "$(pwd)/../{params.cluster_dir}")
        RTD_sleuth_path=$(echo "$(pwd)/../{params.sleuth_dir}")
        input_path=$(echo "$(pwd)/../{params.input_dir}")
        
        python {params.pipeline_dir}/extract.py \
            --clusters "$RTD_clust_path"/clustering_results.tsv \
            --sleuth "$RTD_sleuth_path"/plotting.tsv \
            --alpha {params.alpha} \
            --foldchange {params.foldchange}
            
        {params.pipeline_dir}/fetch_loop.sh \
            --pipeline {params.pipeline_dir} \
            --input "$input_path" \
            --threads {params.threads}
            
        touch retrieval_complete.txt
        """

# Rule for CGR read retrieval
rule cgr_retrieval:
    input:
        sleuth=f"{ACTIVE_DIRS['CGR']['sleuth_dir']}/sleuth_complete.txt"
    output:
        retrieval=f"{ACTIVE_DIRS['CGR']['retrieval_dir']}/retrieval_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        threads = config["threads"],
        alpha = config["alpha"],
        foldchange = config["foldchange"],
        input_dir = "00_input",
        cluster_dir = ACTIVE_DIRS['CGR']['cluster_dir'],
        sleuth_dir = ACTIVE_DIRS['CGR']['sleuth_dir'],
        retrieval_dir = ACTIVE_DIRS['CGR']['retrieval_dir']
    shell:
        """
        echo "\nStarting CGR read retrieval..."
        echo "Mode: {config[embedding]}"
        echo "Cluster directory: {params.cluster_dir}"
        echo "Sleuth directory: {params.sleuth_dir}"
        echo "Output directory: {params.retrieval_dir}"
        
        mkdir -p {params.retrieval_dir}
        cd {params.retrieval_dir}
        
        CGR_clust_path=$(echo "$(pwd)/../{params.cluster_dir}")
        CGR_sleuth_path=$(echo "$(pwd)/../{params.sleuth_dir}")
        input_path=$(echo "$(pwd)/../{params.input_dir}")
        
        python {params.pipeline_dir}/extract.py \
            --clusters "$CGR_clust_path"/clustering_results.tsv \
            --sleuth "$CGR_sleuth_path"/plotting.tsv \
            --alpha {params.alpha} \
            --foldchange {params.foldchange}
            
        {params.pipeline_dir}/fetch_loop.sh \
            --pipeline {params.pipeline_dir} \
            --input "$input_path" \
            --threads {params.threads}
            
        touch retrieval_complete.txt
        """

# Rule for merged results read retrieval
rule merged_retrieval:
    input:
        sleuth=f"{ACTIVE_DIRS['merge']['sleuth_dir']}/sleuth_complete.txt"
    output:
        retrieval=f"{ACTIVE_DIRS['merge']['retrieval_dir']}/retrieval_complete.txt"
    params:
        pipeline_dir = config["pipeline_dir"],
        threads = config["threads"],
        alpha = config["alpha"],
        foldchange = config["foldchange"],
        input_dir = "00_input",
        merge_dir = "05_merging",
        sleuth_dir = ACTIVE_DIRS['merge']['sleuth_dir'],
        retrieval_dir = ACTIVE_DIRS['merge']['retrieval_dir']
    shell:
        """
        echo "\nStarting merged results read retrieval..."
        echo "Merge directory: {params.merge_dir}"
        echo "Sleuth directory: {params.sleuth_dir}"
        echo "Output directory: {params.retrieval_dir}"
        
        mkdir -p {params.retrieval_dir}
        cd {params.retrieval_dir}
        
        merge_path=$(echo "$(pwd)/../{params.merge_dir}")
        merge_sleuth_path=$(echo "$(pwd)/../{params.sleuth_dir}")
        input_path=$(echo "$(pwd)/../{params.input_dir}")
        
        python {params.pipeline_dir}/extract.py \
            --clusters "$merge_path"/merged_clustering_results.tsv \
            --sleuth "$merge_sleuth_path"/plotting.tsv \
            --alpha {params.alpha} \
            --foldchange {params.foldchange}
            
        {params.pipeline_dir}/fetch_loop.sh \
            --pipeline {params.pipeline_dir} \
            --input "$input_path" \
            --threads {params.threads}
            
        touch retrieval_complete.txt
        """
